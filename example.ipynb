{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª set up your environment\n",
    "\n",
    "import `Processor` to restructure and clean your data in a way which allows for rigorous, accurate tuning according to your goals\n",
    "\n",
    "###### ‚ÑπÔ∏è your source data must be csv/json/parquet path OR a dataframe object and contain **at least** one column with plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.filings import Processor\n",
    "source_data_file = \"./raw/kb_export_clean.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìë create chunks from documents\n",
    "\n",
    "we set an an input file with a `Processor` class to create `filings` out of our data\n",
    "\n",
    "###### ‚ÑπÔ∏è you do not need an `id` column, we will make a document-level, integer-wise one for each of your sentences automatically, but keep this in mind for re-indexing your embeddings back to sentences or documents!\n",
    "\n",
    "###### ‚ÑπÔ∏è then we load the raw data file into memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filings = Processor()\n",
    "filings.load(source_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ü•≥ great! let's process our data, _fast_\n",
    "\n",
    "‚ö°Ô∏èüß≤ first we extract sentences for our embedding model to get initial scores and examples which we call `filings`\n",
    "\n",
    "###### ‚ÑπÔ∏è don't forget to declare your plaintext column's name! we do not persist this between objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await filings.process('./data/filings.parquet','clean','file', nlp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ∞Ô∏è next-generation data communication & processing with NATS\n",
    "\n",
    "###### ‚ÑπÔ∏è suppose you have a massive volume of data and this workload needs to be distributed \n",
    "\n",
    "##### `magnet` supports [NATS](https://nats.io) in a clever abstraction for sharing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.ic import field\n",
    "nats_cluster = field.Charge(\"my-user:T0pS3cr3t@192.168.2.69\") # your NATS cluster hostname & basic auth\n",
    "clustered_filings = Processor(field=nats_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß≤ load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_filings.load(source_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß≤ at another workstation, run the following to receive processed data üì°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.ic import field\n",
    "reso = field.Resonator(\"my-user:T0pS3cr3t@192.168.2.69\")\n",
    "await reso.on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß≤ export, but this time your data will also stream to a different node running `magnet` üß≤ as it's being written to the current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await clustered_filings.process('./data/filings.parquet','clean','file', nlp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üéà‚òÅÔ∏è upload to S3\n",
    "\n",
    "upload your entire processed data folder when done (we assume you got your original data from somewhere!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.utils import Utils\n",
    "\n",
    "Utils().upload_to_s3(\n",
    "    './data/'\n",
    "    , ('AWS_CLIENT_KEY', 'AWS_SECRET_KEY')\n",
    "    , 'bucket_name'\n",
    "    , 'finetuning_data'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
