{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = ''\n",
    "\n",
    "# Define the magnet configuration\n",
    "config = {\n",
    "    \"host\": \"\",\n",
    "    \"credentials\": None,\n",
    "    \"domain\": None,\n",
    "    \"stream_name\": username,  # Corrected from \"name\" to \"stream_name\"\n",
    "    \"category\": username,\n",
    "    \"kv_name\": username,\n",
    "    \"session\": username,\n",
    "    \"os_name\": username,\n",
    "    \"index\": {\n",
    "        \"milvus_uri\": \"127.0.0.1\",\n",
    "        \"milvus_port\": 19530,\n",
    "        \"milvus_user\": \"test\",\n",
    "        \"milvus_password\": \"test\",\n",
    "        \"dimension\": 1024,\n",
    "        \"model\": \"BAAI/bge-large-en-v1.5\",\n",
    "        \"name\": \"test\",\n",
    "        \"options\": {\n",
    "            'metric_type': 'COSINE',\n",
    "            'index_type': 'HNSW',\n",
    "            'params': {\n",
    "                \"efConstruction\": 40,\n",
    "                \"M\": 48\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mğŸŒŠ SUCCESS: ğŸ§² connected to \n",
      "ğŸ’ nats://prismadic:prismadic@research.prismadic.ai:4222 \u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: ğŸ§² initialized client \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: Stream dylan_moore not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `dylan_moore` with category `dylan_moore`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: KV bucket dylan_moore not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `dylan_moore`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: KV substore jobs not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `jobs`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: KV substore fabric not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `fabric`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: KV substore runs not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `runs`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: Object Store dylan_moore not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `dylan_moore`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: Object Store jobs not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `jobs`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: Object Store fabric not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `fabric`\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: Object Store runs not found, creating\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: created `runs`\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: ğŸ§² connected to \n",
      "ğŸ’ MagnetConfig(host='prismadic:prismadic@research.prismadic.ai', domain=None, credentials=None, session='dylan_moore', stream_name='dylan_moore', category='dylan_moore', kv_name='dylan_moore', os_name='dylan_moore', index=IndexConfig(milvus_uri='127.0.0.1', milvus_port=19530, milvus_user='test', milvus_password='test', dimension=1024, model='BAAI/bge-large-en-v1.5', name='test', options={'metric_type': 'COSINE', 'index_type': 'HNSW', 'params': {'efConstruction': 40, 'M': 48}})) \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<nats.js.client.JetStreamContext at 0x30a1aa410>,\n",
       " StreamInfo(config=StreamConfig(name='dylan_moore', description=None, subjects=['dylan_moore', 'jobs.>', 'runs.>', 'fabric.>'], retention='limits', max_consumers=-1, max_msgs=-1, max_bytes=-1, discard='old', max_age=0.0, max_msgs_per_subject=-1, max_msg_size=-1, storage='file', num_replicas=1, no_ack=False, template_owner=None, duplicate_window=120.0, placement=None, mirror=None, sources=None, sealed=False, deny_delete=False, deny_purge=False, allow_rollup_hdrs=False, republish=None, allow_direct=False, mirror_direct=False), state=StreamState(messages=0, bytes=0, first_seq=0, last_seq=0, consumer_count=0, deleted=None, num_deleted=None, lost=None), mirror=None, sources=None, cluster=ClusterInfo(leader='rivitt-fabric-nats-2', name='rivitt-fabric-nats', replicas=None), did_create=None),\n",
       " <nats.js.kv.KeyValue at 0x30a261dd0>,\n",
       " <nats.js.kv.KeyValue at 0x30a257d50>,\n",
       " <nats.js.kv.KeyValue at 0x318cba790>,\n",
       " <nats.js.kv.KeyValue at 0x30a1aaf10>,\n",
       " <nats.js.object_store.ObjectStore at 0x318cba450>,\n",
       " <nats.js.object_store.ObjectStore at 0x16968bed0>,\n",
       " <nats.js.object_store.ObjectStore at 0x318cba210>,\n",
       " <nats.js.object_store.ObjectStore at 0x318cba690>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from magnet.base import Magnet\n",
    "from magnet.utils.data_classes import Status\n",
    "from magnet.utils.globals import _f\n",
    "\n",
    "# Define a callback function for status updates\n",
    "def status_callback(status: Status):\n",
    "    _f(status.type,status.content)\n",
    "\n",
    "magnet = Magnet(config, status_callback)\n",
    "await magnet.align()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mâ„¹ï¸ INFO: Created acquire job acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[96mâ˜•ï¸ WAIT: connecting to research.prismadic.ai for role acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: joined worker queue: dylan_moore as Mac for role acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: processing jobs for role [acquire] from [dylan_moore] on\n",
      "ğŸ›°ï¸ object store: dylan_moore\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Handling run of type: acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Starting run acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Claimed job: acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: File found at location: /Users/dylan/VSCode/Rivitt/sample.csv. Reading file...\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: File successfully loaded for id /Users/dylan/VSCode/Rivitt/sample.csv\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Pulsing acquire.dylan_moore.e0426f2f to jobs object store\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: acquire.dylan_moore.e0426f2f successfully pulsed to jobs object store for run acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Run acquire.dylan_moore.e0426f2f stored successfully\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Created acquire job acquire.dylan_moore.e9c8f60f\u001b[0m\n",
      "\u001b[96mâ˜•ï¸ WAIT: connecting to research.prismadic.ai for role acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: joined worker queue: dylan_moore as Mac for role acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: processing jobs for role [acquire] from [dylan_moore] on\n",
      "ğŸ›°ï¸ object store: dylan_moore\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Handling run of type: acquire\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Starting run acquire.dylan_moore.e9c8f60f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Claimed job: acquire.dylan_moore.e9c8f60f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Downloading object acquire.dylan_moore.e0426f2f to /tmp/acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: File downloaded to /tmp/acquire.dylan_moore.e0426f2f\u001b[0m\n",
      "\u001b[92mğŸŒŠ SUCCESS: Object successfully downloaded to /tmp/acquire.dylan_moore.e0426f2f for run acquire.dylan_moore.e9c8f60f\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Run acquire.dylan_moore.e9c8f60f stored successfully\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Created process job process.dylan_moore.f7141eaa\u001b[0m\n",
      "\u001b[96mâ˜•ï¸ WAIT: connecting to research.prismadic.ai for role process\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: joined worker queue: dylan_moore as Mac for role process\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: processing jobs for role [process] from [dylan_moore] on\n",
      "ğŸ›°ï¸ object store: dylan_moore\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Handling run of type: process\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Starting run process.dylan_moore.f7141eaa\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Processing run: process.dylan_moore.f7141eaa\u001b[0m\n",
      "Run(_id='process.dylan_moore.f7141eaa', _job=Job(params=ProcessParams(resource_id='example', location='acquire.dylan_moore.e0426f2f', model='cmamba', data_source='local', processing_options={'chunk_size': 5000, 'timestamp_column': 'timestampRecorded', 'features_to_match': ['Water_Flow', 'flowRate', 'FlowRate'], 'input_length': 250}), _type='process', _id='process.dylan_moore.f7141eaa', _isClaimed=True), _type='process', start_time='2024-08-29T18:43:54.301251+00:00', status='in_progress', end_time=None, results=None, metrics=None)\n",
      "\u001b[94mâ„¹ï¸ INFO: Fitting scaler with cmamba model...\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Starting to fit scaler on data from process.dylan_moore.f7141eaa\u001b[0m\n",
      "\u001b[91mâ˜ ï¸ FATAL: Error during scaler fitting: [Errno 2] No such file or directory: '/tmp/process.dylan_moore.f7141eaa'\u001b[0m\n",
      "\u001b[91mâ˜ ï¸ FATAL: An error occurred while processing run process.dylan_moore.f7141eaa: [Errno 2] No such file or directory: '/tmp/process.dylan_moore.f7141eaa'\u001b[0m\n",
      "\u001b[94mâ„¹ï¸ INFO: Run process.dylan_moore.f7141eaa stored successfully\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainParams.__init__() missing 1 required positional argument: 'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m magnet\u001b[38;5;241m.\u001b[39mresonator\u001b[38;5;241m.\u001b[39mworker(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Process the 'train' job\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Run the workflow\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main(magnet)\n",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(magnet)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m magnet\u001b[38;5;241m.\u001b[39mresonator\u001b[38;5;241m.\u001b[39mworker(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Process the 'process' job\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Step 4: Training Job\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[43mTrainParams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_process_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the ID from the processing job\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Data source for training (e.g., streaming data)\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcmamba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Specify the model to use for training\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Dimension of the model\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_layer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Number of C-Mamba blocks\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq_len\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Length of input sequence (look-back window)\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Number of numerical channels in your data\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatch_len\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Length of each patch\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstride\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Stride for patching\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforecast_len\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Number of future time steps to predict\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md_state\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Dimension of SSM state\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Expansion factor for inner dimension\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdt_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Rank for delta projection, 'auto' sets it to d_model/16\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md_conv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Kernel size for temporal convolution\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpad_multiple\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Padding to ensure sequence length is divisible by this\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Whether to use bias in convolution\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Whether to use bias in linear layers\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msigma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Standard deviation for channel mixup\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreduction_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Reduction ratio for channel attention\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Excite the training job\u001b[39;00m\n\u001b[1;32m     74\u001b[0m pipeline_train_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m magnet\u001b[38;5;241m.\u001b[39mcharge\u001b[38;5;241m.\u001b[39mexcite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_params)\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainParams.__init__() missing 1 required positional argument: 'location'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 49] Can't assign requested address\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 8] nodename nor servname provided, or not known\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: \u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: [Errno 49] Can't assign requested address\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: timeout\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: connection closed\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: connection closed\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: connection closed\u001b[0m\n",
      "\u001b[93mğŸš¨ WARN: nats: connection closed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from magnet.utils.data_classes import AcquireParams, ProcessParams, TrainParams\n",
    "\n",
    "async def main(magnet):\n",
    "    # Step 1: Local Acquisition and Upload\n",
    "    acquire_params_local = AcquireParams(\n",
    "        resource_id=\"example\",  # Resource ID for identification\n",
    "        data_source=\"local\",    # Method to acquire, e.g., \"local\"\n",
    "        location=os.path.expanduser(\"~/VSCode/Rivitt/sample.csv\"),  # Path to the file\n",
    "        acquisition_options={}  # Any additional options (can be expanded as needed)\n",
    "    )\n",
    "\n",
    "    # Excite the acquire job for local file\n",
    "    raw_data_job = await magnet.charge.excite(\"acquire\", acquire_params_local)\n",
    "    await magnet.resonator.worker(role='acquire')  # Process the 'acquire' job\n",
    "\n",
    "    # Step 2: Object Store Acquisition\n",
    "    acquire_params_object_store = AcquireParams(\n",
    "        resource_id=raw_data_job._id,\n",
    "        data_source=\"object_store\",\n",
    "        location=raw_data_job._id,\n",
    "        acquisition_options={}\n",
    "    )\n",
    "\n",
    "    # Excite the acquire job for object store\n",
    "    pipeline_acquire_job = await magnet.charge.excite(\"acquire\", acquire_params_object_store)\n",
    "    await magnet.resonator.worker(role='acquire')  # Process the 'acquire' job\n",
    "\n",
    "    # Step 3: Process the Downloaded File\n",
    "    process_params = ProcessParams(\n",
    "        resource_id=raw_data_job.params.resource_id,  # Use the ID from the object store acquisition job\n",
    "        location=pipeline_acquire_job.params.location,  # Use the location from the object store acquisition job\n",
    "        data_source=\"local\",                   # The data is local after acquisition\n",
    "        model=\"cmamba\",                        # Specify the model to use for processing\n",
    "        processing_options={\n",
    "            \"chunk_size\": 5000,\n",
    "            \"timestamp_column\": \"timestampRecorded\",\n",
    "            \"features_to_match\": [\"Water_Flow\", \"flowRate\", \"FlowRate\"],\n",
    "            \"input_length\": 250\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Excite the process job\n",
    "    pipeline_process_job = await magnet.charge.excite(\"process\", process_params)\n",
    "    await magnet.resonator.worker(role='process')  # Process the 'process' job\n",
    "\n",
    "    # Step 4: Training Job\n",
    "    train_params = TrainParams(\n",
    "        resource_id=pipeline_process_job._id,  # Use the ID from the processing job\n",
    "        data_source=\"stream\",                  # Data source for training (e.g., streaming data)\n",
    "        model=\"cmamba\",                        # Specify the model to use for training\n",
    "        training_options={\n",
    "            \"d_model\": 128,          # Dimension of the model\n",
    "            \"n_layer\": 4,            # Number of C-Mamba blocks\n",
    "            \"seq_len\": 500,          # Length of input sequence (look-back window)\n",
    "            \"num_channels\": 3,       # Number of numerical channels in your data\n",
    "            \"patch_len\": 32,         # Length of each patch\n",
    "            \"stride\": 8,             # Stride for patching\n",
    "            \"forecast_len\": 500,     # Number of future time steps to predict\n",
    "            \"d_state\": 16,           # Dimension of SSM state\n",
    "            \"expand\": 2,             # Expansion factor for inner dimension\n",
    "            \"dt_rank\": 'auto',       # Rank for delta projection, 'auto' sets it to d_model/16\n",
    "            \"d_conv\": 4,             # Kernel size for temporal convolution\n",
    "            \"pad_multiple\": 25,      # Padding to ensure sequence length is divisible by this\n",
    "            \"conv_bias\": True,       # Whether to use bias in convolution\n",
    "            \"bias\": False,           # Whether to use bias in linear layers\n",
    "            \"sigma\": 0.5,            # Standard deviation for channel mixup\n",
    "            \"reduction_ratio\": 4,    # Reduction ratio for channel attention\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Excite the training job\n",
    "    pipeline_train_job = await magnet.charge.excite(\"train\", train_params)\n",
    "    await magnet.resonator.worker(role='train')  # Process the 'train' job\n",
    "\n",
    "# Run the workflow\n",
    "await main(magnet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
